# After testing various public model services (considering factors such as hallucination, inference speed, cost, etc.),
# we recommend using the gemini 2.0 flash, gemini 2.5 flash, and o3-mini, or larger parameter LLMs for testing.
# Additionally, we recommend using DeepSeek V3 deployed on SiliconFlow, which offers advantages of easy access and low API pricing.
LLM_NAME=openai/deepseek-ai/DeepSeek-V3
LLM_ENDPOINT=https://api.siliconflow.cn/v1
LLM_APIKEY=

# Default compatibility with OpenAI API.
EMBEDDING_MODEL_NAME=Qwen/Qwen3-Embedding-4B
EMBEDDING_MODEL_ENDPOINT=https://api.siliconflow.cn/v1/embeddings
EMBEDDING_MODEL_APIKEY=

TEMPERATURE=0
MAX_TOKENS=8192 # required by DeepSeek-V3
PRINT_REASONER_MESSAGES=1
PRINT_SYSTEM_PROMPT=1

LANGUAGE=en-US